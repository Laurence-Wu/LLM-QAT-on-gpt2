{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAT Training Statistics Analysis\n",
    "\n",
    "This notebook analyzes the training statistics from the Quantization-Aware Training (QAT) of GPT-2.\n",
    "\n",
    "## Contents\n",
    "1. Load and inspect training data\n",
    "2. Training loss analysis\n",
    "3. Validation loss analysis\n",
    "4. Memory usage patterns\n",
    "5. Learning rate schedule\n",
    "6. Training efficiency metrics\n",
    "7. Convergence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training statistics\n",
    "def load_training_stats(filepath='part1_switchable_precision/training_stats.json'):\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"‚úÖ Successfully loaded training stats from {filepath}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå File not found: {filepath}\")\n",
    "        print(\"Please ensure the training has been completed and stats file exists.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"‚ùå Invalid JSON in {filepath}\")\n",
    "        return None\n",
    "\n",
    "# Load the data\n",
    "stats = load_training_stats()\n",
    "\n",
    "if stats:\n",
    "    print(f\"\\nüìä Training Statistics Overview:\")\n",
    "    print(f\"  - Total iterations: {len(stats['iterations'])}\")\n",
    "    print(f\"  - Keys available: {list(stats.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "if stats:\n",
    "    df = pd.DataFrame({\n",
    "        'iteration': stats['iterations'],\n",
    "        'train_loss': stats['train_losses'],\n",
    "        'val_loss': stats.get('val_losses', [None] * len(stats['iterations'])),\n",
    "        'learning_rate': stats.get('learning_rates', [None] * len(stats['iterations'])),\n",
    "        'memory_mb': stats.get('memory_usage', [None] * len(stats['iterations']))\n",
    "    })\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(\"\\nüìà Dataset Summary:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nüîç First 5 rows:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    print(\"\\nüîç Last 5 rows:\")\n",
    "    display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Loss Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stats:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Raw training loss\n",
    "    axes[0].plot(df['iteration'], df['train_loss'], alpha=0.6, label='Raw Loss')\n",
    "    \n",
    "    # Add smoothed line if enough data points\n",
    "    if len(df) > 50:\n",
    "        window_size = min(51, len(df) // 10 * 2 + 1)  # Ensure odd window size\n",
    "        smoothed = savgol_filter(df['train_loss'].dropna(), window_size, 3)\n",
    "        axes[0].plot(df['iteration'][:len(smoothed)], smoothed, 'r-', linewidth=2, label='Smoothed')\n",
    "    \n",
    "    axes[0].set_xlabel('Iteration')\n",
    "    axes[0].set_ylabel('Training Loss')\n",
    "    axes[0].set_title('Training Loss Over Time')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Loss distribution\n",
    "    axes[1].hist(df['train_loss'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvline(df['train_loss'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"train_loss\"].mean():.4f}')\n",
    "    axes[1].axvline(df['train_loss'].median(), color='green', linestyle='--', label=f'Median: {df[\"train_loss\"].median():.4f}')\n",
    "    axes[1].set_xlabel('Loss Value')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Training Loss Distribution')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate improvement metrics\n",
    "    initial_loss = df['train_loss'].iloc[:10].mean()\n",
    "    final_loss = df['train_loss'].iloc[-10:].mean()\n",
    "    improvement = (initial_loss - final_loss) / initial_loss * 100\n",
    "    \n",
    "    print(f\"\\nüìä Training Loss Metrics:\")\n",
    "    print(f\"  - Initial loss (first 10 iter): {initial_loss:.4f}\")\n",
    "    print(f\"  - Final loss (last 10 iter): {final_loss:.4f}\")\n",
    "    print(f\"  - Improvement: {improvement:.2f}%\")\n",
    "    print(f\"  - Minimum loss: {df['train_loss'].min():.4f} at iteration {df.loc[df['train_loss'].idxmin(), 'iteration']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation Loss Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stats and 'val_losses' in stats:\n",
    "    # Filter out None values for validation loss\n",
    "    val_df = df[df['val_loss'].notna()].copy()\n",
    "    \n",
    "    if not val_df.empty:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Plot 1: Training vs Validation Loss\n",
    "        axes[0].plot(df['iteration'], df['train_loss'], alpha=0.6, label='Training Loss')\n",
    "        axes[0].scatter(val_df['iteration'], val_df['val_loss'], color='red', s=30, label='Validation Loss', zorder=5)\n",
    "        axes[0].plot(val_df['iteration'], val_df['val_loss'], 'r--', alpha=0.5)\n",
    "        axes[0].set_xlabel('Iteration')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].set_title('Training vs Validation Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Overfitting Analysis (Gap between train and val)\n",
    "        # Interpolate training loss at validation points\n",
    "        train_at_val = np.interp(val_df['iteration'], df['iteration'], df['train_loss'])\n",
    "        gap = val_df['val_loss'].values - train_at_val\n",
    "        \n",
    "        axes[1].plot(val_df['iteration'], gap, 'o-', color='purple')\n",
    "        axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        axes[1].fill_between(val_df['iteration'], 0, gap, alpha=0.3, color='purple')\n",
    "        axes[1].set_xlabel('Iteration')\n",
    "        axes[1].set_ylabel('Validation - Training Loss')\n",
    "        axes[1].set_title('Generalization Gap (Overfitting Indicator)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        print(f\"\\nüìä Validation Metrics:\")\n",
    "        print(f\"  - Best validation loss: {val_df['val_loss'].min():.4f} at iteration {val_df.loc[val_df['val_loss'].idxmin(), 'iteration']}\")\n",
    "        print(f\"  - Average generalization gap: {gap.mean():.4f}\")\n",
    "        print(f\"  - Final generalization gap: {gap[-1]:.4f}\")\n",
    "        \n",
    "        if gap[-1] > gap[0]:\n",
    "            print(f\"  ‚ö†Ô∏è Warning: Increasing generalization gap (potential overfitting)\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ Good: Stable or decreasing generalization gap\")\n",
    "    else:\n",
    "        print(\"No validation data available in the statistics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Memory Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stats and 'memory_usage' in stats:\n",
    "    mem_df = df[df['memory_mb'].notna()].copy()\n",
    "    \n",
    "    if not mem_df.empty:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # Plot 1: Memory usage over time\n",
    "        axes[0].plot(mem_df['iteration'], mem_df['memory_mb'], 'b-', alpha=0.7)\n",
    "        axes[0].fill_between(mem_df['iteration'], mem_df['memory_mb'].min(), mem_df['memory_mb'], alpha=0.3)\n",
    "        axes[0].set_xlabel('Iteration')\n",
    "        axes[0].set_ylabel('Memory Usage (MB)')\n",
    "        axes[0].set_title('GPU Memory Usage Over Time')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add memory leak detection line\n",
    "        z = np.polyfit(mem_df['iteration'], mem_df['memory_mb'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[0].plot(mem_df['iteration'], p(mem_df['iteration']), \"r--\", alpha=0.5, label=f'Trend: {z[0]:.2f} MB/iter')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Plot 2: Memory distribution\n",
    "        axes[1].hist(mem_df['memory_mb'], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "        axes[1].axvline(mem_df['memory_mb'].mean(), color='red', linestyle='--', label=f'Mean: {mem_df[\"memory_mb\"].mean():.0f} MB')\n",
    "        axes[1].set_xlabel('Memory Usage (MB)')\n",
    "        axes[1].set_ylabel('Frequency')\n",
    "        axes[1].set_title('Memory Usage Distribution')\n",
    "        axes[1].legend()\n",
    "        \n",
    "        # Plot 3: Memory vs Loss correlation\n",
    "        axes[2].scatter(mem_df['memory_mb'], mem_df['train_loss'], alpha=0.5)\n",
    "        axes[2].set_xlabel('Memory Usage (MB)')\n",
    "        axes[2].set_ylabel('Training Loss')\n",
    "        axes[2].set_title('Memory Usage vs Training Loss')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add correlation coefficient\n",
    "        corr = mem_df['memory_mb'].corr(mem_df['train_loss'])\n",
    "        axes[2].text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=axes[2].transAxes, \n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Memory statistics\n",
    "        print(f\"\\nüíæ Memory Usage Statistics:\")\n",
    "        print(f\"  - Average memory: {mem_df['memory_mb'].mean():.0f} MB\")\n",
    "        print(f\"  - Peak memory: {mem_df['memory_mb'].max():.0f} MB\")\n",
    "        print(f\"  - Memory variance: {mem_df['memory_mb'].std():.0f} MB\")\n",
    "        print(f\"  - Memory growth rate: {z[0]:.4f} MB/iteration\")\n",
    "        \n",
    "        if abs(z[0]) < 0.1:\n",
    "            print(f\"  ‚úÖ No significant memory leak detected\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è Potential memory leak: {z[0]:.4f} MB/iteration growth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Learning Rate Schedule Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stats and 'learning_rates' in stats:\n",
    "    lr_df = df[df['learning_rate'].notna()].copy()\n",
    "    \n",
    "    if not lr_df.empty:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Plot 1: Learning rate schedule\n",
    "        axes[0].plot(lr_df['iteration'], lr_df['learning_rate'], 'g-', linewidth=2)\n",
    "        axes[0].set_xlabel('Iteration')\n",
    "        axes[0].set_ylabel('Learning Rate')\n",
    "        axes[0].set_title('Learning Rate Schedule (Cosine Annealing)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        axes[0].set_yscale('log')\n",
    "        \n",
    "        # Plot 2: Learning rate vs Loss\n",
    "        scatter = axes[1].scatter(lr_df['learning_rate'], lr_df['train_loss'], \n",
    "                                 c=lr_df['iteration'], cmap='viridis', alpha=0.6)\n",
    "        axes[1].set_xlabel('Learning Rate')\n",
    "        axes[1].set_ylabel('Training Loss')\n",
    "        axes[1].set_title('Learning Rate vs Training Loss')\n",
    "        axes[1].set_xscale('log')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=axes[1])\n",
    "        cbar.set_label('Iteration')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nüéØ Learning Rate Statistics:\")\n",
    "        print(f\"  - Initial LR: {lr_df['learning_rate'].iloc[0]:.6f}\")\n",
    "        print(f\"  - Final LR: {lr_df['learning_rate'].iloc[-1]:.6f}\")\n",
    "        print(f\"  - LR reduction: {(1 - lr_df['learning_rate'].iloc[-1]/lr_df['learning_rate'].iloc[0])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stats:\n",
    "    # Calculate various efficiency metrics\n",
    "    \n",
    "    # Loss reduction rate\n",
    "    window = min(50, len(df) // 10)\n",
    "    loss_changes = df['train_loss'].rolling(window=window).mean().diff()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Loss reduction rate\n",
    "    axes[0, 0].plot(df['iteration'][window:], loss_changes[window:], alpha=0.7)\n",
    "    axes[0, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Loss Change Rate')\n",
    "    axes[0, 0].set_title(f'Training Loss Change Rate (window={window})')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Cumulative loss reduction\n",
    "    cumulative_improvement = (df['train_loss'].iloc[0] - df['train_loss']) / df['train_loss'].iloc[0] * 100\n",
    "    axes[0, 1].plot(df['iteration'], cumulative_improvement, 'b-', linewidth=2)\n",
    "    axes[0, 1].fill_between(df['iteration'], 0, cumulative_improvement, alpha=0.3)\n",
    "    axes[0, 1].set_xlabel('Iteration')\n",
    "    axes[0, 1].set_ylabel('Improvement (%)')\n",
    "    axes[0, 1].set_title('Cumulative Loss Improvement')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Training stability (loss variance over windows)\n",
    "    loss_variance = df['train_loss'].rolling(window=window).std()\n",
    "    axes[1, 0].plot(df['iteration'][window:], loss_variance[window:], 'orange', alpha=0.7)\n",
    "    axes[1, 0].set_xlabel('Iteration')\n",
    "    axes[1, 0].set_ylabel('Loss Std Dev')\n",
    "    axes[1, 0].set_title(f'Training Stability (Loss Variance, window={window})')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Iterations per loss unit\n",
    "    loss_ranges = np.arange(df['train_loss'].min(), df['train_loss'].max(), 0.1)\n",
    "    iterations_needed = []\n",
    "    for i in range(len(loss_ranges)-1):\n",
    "        mask = (df['train_loss'] >= loss_ranges[i]) & (df['train_loss'] < loss_ranges[i+1])\n",
    "        iterations_needed.append(mask.sum())\n",
    "    \n",
    "    axes[1, 1].bar(loss_ranges[:-1], iterations_needed, width=0.09, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 1].set_xlabel('Loss Range')\n",
    "    axes[1, 1].set_ylabel('Number of Iterations')\n",
    "    axes[1, 1].set_title('Iterations Spent in Each Loss Range')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate efficiency metrics\n",
    "    early_improvement = cumulative_improvement.iloc[len(df)//4]\n",
    "    late_improvement = cumulative_improvement.iloc[-1] - cumulative_improvement.iloc[3*len(df)//4]\n",
    "    \n",
    "    print(f\"\\n‚ö° Training Efficiency Metrics:\")\n",
    "    print(f\"  - Early training improvement (first 25%): {early_improvement:.2f}%\")\n",
    "    print(f\"  - Late training improvement (last 25%): {late_improvement:.2f}%\")\n",
    "    print(f\"  - Average loss variance: {loss_variance.mean():.4f}\")\n",
    "    print(f\"  - Training stability score: {1/(1+loss_variance.mean()):.3f} (higher is better)\")\n",
    "    \n",
    "    if early_improvement > late_improvement * 2:\n",
    "        print(f\"  ‚úÖ Efficient early training - most learning happened early\")\n",
    "    else:\n",
    "        print(f\"  üìà Continued learning throughout training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stats:\n",
    "    # Convergence analysis\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Loss convergence with exponential fit\n",
    "    from scipy.optimize import curve_fit\n",
    "    \n",
    "    def exp_decay(x, a, b, c):\n",
    "        return a * np.exp(-b * x) + c\n",
    "    \n",
    "    try:\n",
    "        # Fit exponential decay\n",
    "        x_data = df['iteration'].values\n",
    "        y_data = df['train_loss'].values\n",
    "        \n",
    "        # Initial guess\n",
    "        p0 = [y_data[0] - y_data[-1], 0.001, y_data[-1]]\n",
    "        popt, pcov = curve_fit(exp_decay, x_data, y_data, p0=p0, maxfev=5000)\n",
    "        \n",
    "        # Plot actual and fitted\n",
    "        axes[0].plot(x_data, y_data, 'b-', alpha=0.5, label='Actual Loss')\n",
    "        axes[0].plot(x_data, exp_decay(x_data, *popt), 'r-', linewidth=2, \n",
    "                    label=f'Fitted: {popt[0]:.3f}*exp(-{popt[1]:.4f}*x)+{popt[2]:.3f}')\n",
    "        axes[0].set_xlabel('Iteration')\n",
    "        axes[0].set_ylabel('Training Loss')\n",
    "        axes[0].set_title('Loss Convergence with Exponential Fit')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Estimate convergence point (where decay is < 0.001 per iteration)\n",
    "        convergence_iter = -np.log(0.001 / popt[0]) / popt[1] if popt[1] > 0 else np.inf\n",
    "        if convergence_iter < len(df) * 2:\n",
    "            axes[0].axvline(x=convergence_iter, color='green', linestyle='--', \n",
    "                          label=f'Est. Convergence: {convergence_iter:.0f}')\n",
    "            axes[0].legend()\n",
    "            \n",
    "    except:\n",
    "        axes[0].plot(df['iteration'], df['train_loss'], 'b-', alpha=0.7)\n",
    "        axes[0].set_xlabel('Iteration')\n",
    "        axes[0].set_ylabel('Training Loss')\n",
    "        axes[0].set_title('Training Loss (Exponential fit failed)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Gradient magnitude estimate (loss changes)\n",
    "    grad_estimate = np.abs(df['train_loss'].diff())\n",
    "    window_size = min(51, len(df) // 10 * 2 + 1)\n",
    "    if len(grad_estimate) > window_size:\n",
    "        grad_smooth = savgol_filter(grad_estimate.dropna(), window_size, 3)\n",
    "        axes[1].plot(df['iteration'][1:len(grad_smooth)+1], grad_smooth, 'purple', linewidth=2)\n",
    "    axes[1].set_xlabel('Iteration')\n",
    "    axes[1].set_ylabel('|Loss Change|')\n",
    "    axes[1].set_title('Estimated Gradient Magnitude (Loss Change Rate)')\n",
    "    axes[1].set_yscale('log')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Convergence metrics\n",
    "    last_100_std = df['train_loss'].iloc[-100:].std() if len(df) > 100 else df['train_loss'].std()\n",
    "    last_100_mean = df['train_loss'].iloc[-100:].mean() if len(df) > 100 else df['train_loss'].mean()\n",
    "    \n",
    "    print(f\"\\nüéØ Convergence Analysis:\")\n",
    "    print(f\"  - Final loss stability (std of last 100): {last_100_std:.5f}\")\n",
    "    print(f\"  - Final loss mean (last 100): {last_100_mean:.4f}\")\n",
    "    \n",
    "    if 'popt' in locals():\n",
    "        print(f\"  - Exponential decay rate: {popt[1]:.5f}\")\n",
    "        print(f\"  - Asymptotic loss (predicted): {popt[2]:.4f}\")\n",
    "        if convergence_iter < len(df) * 2:\n",
    "            print(f\"  - Estimated convergence iteration: {convergence_iter:.0f}\")\n",
    "            if convergence_iter < len(df):\n",
    "                print(f\"  ‚úÖ Model has likely converged\")\n",
    "            else:\n",
    "                print(f\"  üìà Model approaching convergence\")\n",
    "    \n",
    "    if last_100_std < 0.01:\n",
    "        print(f\"  ‚úÖ Training has converged (low variance in final iterations)\")\n",
    "    else:\n",
    "        print(f\"  üìà Training still showing variation (may benefit from more iterations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stats:\n",
    "    print(\"=\"*60)\n",
    "    print(\"üìä TRAINING SUMMARY REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Key metrics\n",
    "    print(\"\\nüîë Key Metrics:\")\n",
    "    print(f\"  - Total iterations: {len(df)}\")\n",
    "    print(f\"  - Final training loss: {df['train_loss'].iloc[-1]:.4f}\")\n",
    "    print(f\"  - Best training loss: {df['train_loss'].min():.4f}\")\n",
    "    print(f\"  - Total improvement: {(1 - df['train_loss'].iloc[-1]/df['train_loss'].iloc[0])*100:.2f}%\")\n",
    "    \n",
    "    if 'val_losses' in stats and any(v is not None for v in stats['val_losses']):\n",
    "        val_df = df[df['val_loss'].notna()]\n",
    "        print(f\"  - Best validation loss: {val_df['val_loss'].min():.4f}\")\n",
    "        print(f\"  - Final validation loss: {val_df['val_loss'].iloc[-1]:.4f}\")\n",
    "    \n",
    "    # Training quality assessment\n",
    "    print(\"\\n‚úÖ Training Quality Assessment:\")\n",
    "    \n",
    "    quality_score = 0\n",
    "    max_score = 0\n",
    "    \n",
    "    # Check 1: Loss improvement\n",
    "    improvement = (1 - df['train_loss'].iloc[-1]/df['train_loss'].iloc[0])\n",
    "    max_score += 1\n",
    "    if improvement > 0.3:\n",
    "        print(f\"  ‚úì Good loss improvement ({improvement*100:.1f}%)\")\n",
    "        quality_score += 1\n",
    "    else:\n",
    "        print(f\"  ‚úó Limited loss improvement ({improvement*100:.1f}%)\")\n",
    "    \n",
    "    # Check 2: Training stability\n",
    "    final_std = df['train_loss'].iloc[-100:].std() if len(df) > 100 else df['train_loss'].std()\n",
    "    max_score += 1\n",
    "    if final_std < 0.05:\n",
    "        print(f\"  ‚úì Stable training (std={final_std:.4f})\")\n",
    "        quality_score += 1\n",
    "    else:\n",
    "        print(f\"  ‚úó Unstable training (std={final_std:.4f})\")\n",
    "    \n",
    "    # Check 3: No memory leaks\n",
    "    if 'memory_usage' in stats:\n",
    "        mem_df = df[df['memory_mb'].notna()]\n",
    "        if not mem_df.empty:\n",
    "            z = np.polyfit(mem_df['iteration'], mem_df['memory_mb'], 1)\n",
    "            max_score += 1\n",
    "            if abs(z[0]) < 0.5:\n",
    "                print(f\"  ‚úì No memory leaks detected\")\n",
    "                quality_score += 1\n",
    "            else:\n",
    "                print(f\"  ‚úó Potential memory leak ({z[0]:.2f} MB/iter)\")\n",
    "    \n",
    "    # Check 4: Convergence\n",
    "    max_score += 1\n",
    "    if final_std < 0.01:\n",
    "        print(f\"  ‚úì Training converged\")\n",
    "        quality_score += 1\n",
    "    else:\n",
    "        print(f\"  ‚úó Training not fully converged\")\n",
    "    \n",
    "    # Overall score\n",
    "    print(f\"\\nüèÜ Overall Training Quality Score: {quality_score}/{max_score} ({quality_score/max_score*100:.0f}%)\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"\\nüí° Recommendations:\")\n",
    "    \n",
    "    if final_std > 0.01:\n",
    "        print(\"  ‚Ä¢ Consider training for more iterations to achieve full convergence\")\n",
    "    \n",
    "    if 'val_losses' in stats:\n",
    "        val_df = df[df['val_loss'].notna()]\n",
    "        if not val_df.empty:\n",
    "            train_at_val = np.interp(val_df['iteration'], df['iteration'], df['train_loss'])\n",
    "            final_gap = val_df['val_loss'].iloc[-1] - train_at_val[-1]\n",
    "            if final_gap > 0.5:\n",
    "                print(\"  ‚Ä¢ High generalization gap - consider regularization or more data\")\n",
    "    \n",
    "    if improvement < 0.2:\n",
    "        print(\"  ‚Ä¢ Limited improvement - consider adjusting learning rate or model architecture\")\n",
    "    \n",
    "    if 'memory_usage' in stats and abs(z[0]) > 0.5:\n",
    "        print(\"  ‚Ä¢ Memory leak detected - review memory management in training loop\")\n",
    "    \n",
    "    if quality_score == max_score:\n",
    "        print(\"  ‚Ä¢ Excellent training run! Model is ready for deployment.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. CPT (Cyclic Precision Training) Analysis\n\nThis section analyzes statistics from Cyclic Precision Training if available."
  },
  {
   "cell_type": "code",
   "source": "# Load CPT training statistics\ndef load_cpt_stats(filepath=None):\n    \"\"\"Load CPT training statistics from JSON file.\"\"\"\n    if filepath is None:\n        # Try to find the most recent CPT stats file\n        import glob\n        import os\n        cpt_files = glob.glob('cpt_training_stats_*.json')\n        if not cpt_files:\n            cpt_files = glob.glob('part2_cyclic_precision/cpt_training_stats_*.json')\n        \n        if cpt_files:\n            # Get the most recent file\n            filepath = max(cpt_files, key=os.path.getctime)\n            print(f\"Found CPT stats file: {filepath}\")\n        else:\n            print(\"No CPT training statistics file found\")\n            return None\n    \n    try:\n        with open(filepath, 'r') as f:\n            data = json.load(f)\n        print(f\"‚úÖ Successfully loaded CPT stats from {filepath}\")\n        return data\n    except Exception as e:\n        print(f\"‚ùå Error loading CPT stats: {e}\")\n        return None\n\n# Try to load CPT stats\ncpt_stats = load_cpt_stats()\n\nif cpt_stats:\n    print(f\"\\nüìä CPT Training Statistics Overview:\")\n    print(f\"  - Total iterations: {len(cpt_stats.get('iteration_losses', []))}\")\n    print(f\"  - Keys available: {list(cpt_stats.keys())}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Analyze CPT bit-width cycling patterns\nif cpt_stats and 'bit_width_history' in cpt_stats:\n    bit_history = cpt_stats['bit_width_history']\n    iterations = list(range(len(bit_history)))\n    \n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # Plot 1: Bit-width over time\n    axes[0, 0].plot(iterations, bit_history, 'g-', linewidth=2, alpha=0.7)\n    axes[0, 0].set_xlabel('Iteration')\n    axes[0, 0].set_ylabel('Bit Width')\n    axes[0, 0].set_title('Bit-Width Cycling Pattern')\n    axes[0, 0].set_ylim([0, max(bit_history) + 1])\n    axes[0, 0].grid(True, alpha=0.3)\n    axes[0, 0].set_yticks(sorted(set(bit_history)))\n    \n    # Plot 2: Loss vs Bit-width\n    if 'iteration_losses' in cpt_stats:\n        losses = cpt_stats['iteration_losses'][:len(bit_history)]\n        \n        # Create scatter plot colored by iteration\n        scatter = axes[0, 1].scatter(bit_history, losses, c=iterations, \n                                    cmap='viridis', alpha=0.6, s=20)\n        axes[0, 1].set_xlabel('Bit Width')\n        axes[0, 1].set_ylabel('Training Loss')\n        axes[0, 1].set_title('Loss vs Bit-Width')\n        axes[0, 1].grid(True, alpha=0.3)\n        plt.colorbar(scatter, ax=axes[0, 1], label='Iteration')\n        \n        # Calculate average loss per bit-width\n        bit_values = sorted(set(bit_history))\n        avg_losses = []\n        for bit in bit_values:\n            bit_losses = [losses[i] for i, b in enumerate(bit_history) if b == bit]\n            avg_losses.append(np.mean(bit_losses))\n        \n        axes[1, 0].bar(bit_values, avg_losses, alpha=0.7, edgecolor='black')\n        axes[1, 0].set_xlabel('Bit Width')\n        axes[1, 0].set_ylabel('Average Loss')\n        axes[1, 0].set_title('Average Loss per Bit-Width')\n        axes[1, 0].grid(True, alpha=0.3)\n        \n        # Plot 4: Bit-width distribution\n        axes[1, 1].hist(bit_history, bins=len(set(bit_history)), \n                       alpha=0.7, edgecolor='black', color='orange')\n        axes[1, 1].set_xlabel('Bit Width')\n        axes[1, 1].set_ylabel('Frequency')\n        axes[1, 1].set_title('Bit-Width Distribution')\n        axes[1, 1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Statistics\n    print(f\"\\nüîÑ CPT Bit-Width Statistics:\")\n    print(f\"  - Unique bit widths used: {sorted(set(bit_history))}\")\n    print(f\"  - Most common bit width: {max(set(bit_history), key=bit_history.count)}\")\n    print(f\"  - Average bit width: {np.mean(bit_history):.2f}\")\n    \n    if 'iteration_losses' in cpt_stats:\n        print(f\"\\nüìä Loss per Bit-Width:\")\n        for bit, avg_loss in zip(bit_values, avg_losses):\n            print(f\"  - {bit}-bit: {avg_loss:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "## 10. Export Analysis Results",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results to a file\n",
    "if stats:\n",
    "    analysis_results = {\n",
    "        'total_iterations': len(df),\n",
    "        'final_train_loss': float(df['train_loss'].iloc[-1]),\n",
    "        'best_train_loss': float(df['train_loss'].min()),\n",
    "        'improvement_percentage': float((1 - df['train_loss'].iloc[-1]/df['train_loss'].iloc[0])*100),\n",
    "        'training_stable': bool(df['train_loss'].iloc[-100:].std() < 0.05 if len(df) > 100 else False),\n",
    "        'converged': bool(df['train_loss'].iloc[-100:].std() < 0.01 if len(df) > 100 else False)\n",
    "    }\n",
    "    \n",
    "    if 'val_losses' in stats:\n",
    "        val_df = df[df['val_loss'].notna()]\n",
    "        if not val_df.empty:\n",
    "            analysis_results['best_val_loss'] = float(val_df['val_loss'].min())\n",
    "            analysis_results['final_val_loss'] = float(val_df['val_loss'].iloc[-1])\n",
    "    \n",
    "    # Save to JSON\n",
    "    with open('training_analysis_results.json', 'w') as f:\n",
    "        json.dump(analysis_results, f, indent=2)\n",
    "    \n",
    "    print(\"‚úÖ Analysis results saved to 'training_analysis_results.json'\")\n",
    "    print(\"\\nResults summary:\")\n",
    "    for key, value in analysis_results.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}